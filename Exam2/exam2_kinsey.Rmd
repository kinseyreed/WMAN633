---
title: "exam2"
author: "Kinsey Reed"
date: "3/22/2021"
output: html_document
---

10 questions, 5 points each
Included with this exam is a dataset called “Exam 2 Data.csv”, with the following variables:
y: count of events
x1: predictor variable, continuous
x2: predictor variable, continuous
x3: categorical variable with 3 levels: "a", "b", and "c"

Use this dataset to answer the following questions:

1. Import this dataset into R and inspect the first several rows of your data

```{r}
data <- read.csv('Exam 2 Data.csv', header= T)
head(data)
```
2. Fit a Poisson model that assumes your response is a function of x1, x2, and x3. Include an interaction
between x1 and x2 only (i.e., do not include an interaction between your categorical variables and any
other variables).


```{r}
fit <- glm(y ~ x1 * x2 + x3, family = poisson, data = data)
summary(fit)
```

3. Interpret the effect of variable x1 when x2 = -1


$$ y = \beta_0 + \beta_1~x_1 + \beta_2~x_2 + \beta_3~x_3b + \beta_4~x_3c + \beta_5~x_1~x_2$$

$$ y = \beta_0 + x_1(\beta_1 + \beta_5~x_2) + \beta_2~x_2 + \beta_3~x_3b + \beta_4~x_3c $$

Effective slope = $$ \beta_1 + \beta_5~x_2 $$


```{r}
B <- coef(fit)

#log expected count
B[2] + B[6] * -1


#the proportional change in expected count
exp(B[2] + B[6] * -1)

#% 
(exp(B[2] + B[4] * -1) - 1) * 100

```

So, the proportional change in expected count decreases by ~76% or 0.75 for every one unit increase in x1.

4. Plot expected counts ±90% confidence intervals over the observed range of variable x1. Assume variable
when x2 = -1 and category "a".

```{r}
df <- data.frame(
  x1 = seq(min(data$x1), max(data$x1), length.out = 100),
  x3 = factor(x = rep('a', times = 100),
               levels = c('a', 'b', 'c')),
  x2 = rep(-1, times = 100)
)

#predict
prd <- predict.glm(object = fit, type = 'link', newdata = df, se.fit = T)
low <- exp(prd$fit - qnorm(0.95) * prd$se.fit)
high <- exp(prd$fit + qnorm(0.95) * prd$se.fit)

#plotting
plot(y = exp(prd$fit), x = df$x1, xlab = 'x1',
     ylab = 'Expected Count', cex.axis = 1.5, cex.lab = 1.5,
     ylim = c(min(low), max(high)), type = 'l')
lines(x = df$x1, y = low, lty = 2)
lines(x = df$x1, y = high, lty = 2)


```




5. Interpret the effect of variable x3

The difference in log expected count between category b and a is 0.375. The difference in log expected count between category c and a is -0.88. 

```{r}
summary(fit)


```

6. Use contrasts to evaluate the null hypothesis that the difference in log expected count between levels
"b" and "c" = 0. Fix x1 and x2 at their means.


P value means we will reject our null hypothesis that diff between b and c = 0.
```{r}
library(multcomp)

m <- matrix(c(0, 0, 0, 1, 1, 0), nrow = 1)

cnt <- glht(fit, m)
summary(cnt, test = adjusted('none'))

```



7. Derive the test statistic and p-value associated with the interaction between x1 and x2. What is the
null hypothesis? Do we reject or fail to reject this null hypothesis? Defend your answer.

```{r}
s <- summary(fit)[['coefficients']][, 2]

# test statistic
B[6] / s[6]

# p-value
pnorm(-1 * abs(B[6] / s[6])) * 2
```
The null hypothesis is that β5 = 0. We reject the null hypothesis because the p-value is well below 0.05. Meaning that there is evidence that the effect of variable x1 depends on the level of x2. β5 is the change in effective slope coefficient of x1 associated with a 1-unit change in x2.




Other Questions
8. assume you have the following realizations of random variable Y :
y = (1, 0)
Further assume realizations of the random variable Y are Bernoulli distributed:
y ∼ Bernoulli(p).
What is the probability of observing each of these random variables assuming the log odds of success =
-2?
```{r}
dbinom(0, size = 1, prob = exp(-2))
dbinom(1, size = 1, prob = exp(-2))
```
9. What is the "support" of a Bernoulli random variable? What are the acceptable values of it’s sole
parameter? To which quantity do we apply a link function, and why do we do this? What is the
principle link function we use in binomial (i.e., logistic) regression, and what it it’s inverse function?


Bernoulli random variables are either 0 or 1. i.e. support = Y E{0,1}. It's only acceptable values are 0 or 1. We apply a link function to the parameter that describes the possible outcomes. We do this so we can map that number to the real number line. For binomial regression, we use the logit link function or x = log(p/1-0) and the inverse logit link function p = exp(x)/1+exp(x)


10. What is a fundamental assumption we make to derive inference when comparing two levels of a
categorical random variable?

That they are linear combinations of gaussian random variables. 
